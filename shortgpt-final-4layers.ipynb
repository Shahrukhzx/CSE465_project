{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets lm_eval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:55:33.273125Z","iopub.execute_input":"2025-03-15T11:55:33.273404Z","iopub.status.idle":"2025-03-15T11:55:48.051101Z","shell.execute_reply.started":"2025-03-15T11:55:33.273381Z","shell.execute_reply":"2025-03-15T11:55:48.050309Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting lm_eval\n  Downloading lm_eval-0.4.8-py3-none-any.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval) (1.2.1)\nCollecting evaluate (from lm_eval)\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting jsonlines (from lm_eval)\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval) (2.10.2)\nRequirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval) (0.14.0)\nRequirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from lm_eval) (2.13.6)\nCollecting pytablewriter (from lm_eval)\n  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\nCollecting rouge-score>=0.0.4 (from lm_eval)\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting sacrebleu>=1.5.0 (from lm_eval)\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval) (1.2.2)\nCollecting sqlitedict (from lm_eval)\n  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm_eval) (2.5.1+cu121)\nCollecting tqdm-multiprocess (from lm_eval)\n  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval) (4.47.0)\nCollecting zstandard (from lm_eval)\n  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting word2number (from lm_eval)\n  Downloading word2number-1.1.zip (9.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from lm_eval) (10.5.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm_eval) (5.9.5)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm_eval) (0.4.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval) (1.17.0)\nCollecting portalocker (from sacrebleu>=1.5.0->lm_eval)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval) (5.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval) (3.5.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8->lm_eval) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm_eval) (0.21.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval) (75.1.0)\nCollecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval)\n  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\nCollecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval)\n  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\nCollecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval)\n  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\nCollecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval)\n  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\nCollecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval)\n  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\nCollecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval)\n  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval) (5.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm_eval) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading lm_eval-0.4.8-py3-none-any.whl (3.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nDownloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\nDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\nDownloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\nDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\nDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\nDownloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\nDownloading typepy-1.3.4-py3-none-any.whl (31 kB)\nDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: rouge-score, sqlitedict, word2number\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=1b7b73715a6b1c9b844edf1ecd1015c88557b6d49710bf9a80aa7d94f3fc2f91\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=744202ddab75c98c47bacdf1e5639be1bc1c75121d01e6d29442948734add37b\n  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=b55864b4cc6045ce2d42061800a5b1704aca43701e23ba13d69e30ac801df866\n  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\nSuccessfully built rouge-score sqlitedict word2number\nInstalling collected packages: word2number, sqlitedict, zstandard, tqdm-multiprocess, tcolorpy, portalocker, pathvalidate, mbstrdecoder, jsonlines, typepy, DataProperty, tabledata, pytablewriter, sacrebleu, rouge-score, evaluate, lm_eval\nSuccessfully installed DataProperty-1.1.0 evaluate-0.4.3 jsonlines-4.0.0 lm_eval-0.4.8 mbstrdecoder-1.1.4 pathvalidate-3.2.3 portalocker-3.1.1 pytablewriter-1.2.1 rouge-score-0.1.2 sacrebleu-2.5.1 sqlitedict-2.1.0 tabledata-1.3.4 tcolorpy-0.1.7 tqdm-multiprocess-0.0.11 typepy-1.3.4 word2number-1.1 zstandard-0.23.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# importing the required libraries\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, Trainer, TrainingArguments\nfrom collections import OrderedDict\nfrom typing import List, Optional\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom datasets import load_dataset\nimport torch\nfrom torch.utils.data import DataLoader\nfrom lm_eval import evaluator, tasks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:55:48.052047Z","iopub.execute_input":"2025-03-15T11:55:48.052355Z","iopub.status.idle":"2025-03-15T11:56:11.087829Z","shell.execute_reply.started":"2025-03-15T11:55:48.052332Z","shell.execute_reply":"2025-03-15T11:56:11.087111Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:56:11.088489Z","iopub.execute_input":"2025-03-15T11:56:11.088701Z","iopub.status.idle":"2025-03-15T11:56:11.115810Z","shell.execute_reply.started":"2025-03-15T11:56:11.088683Z","shell.execute_reply":"2025-03-15T11:56:11.114927Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bed1d84e4d64a8ea12a486833e965d6"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def layer_removal(\n    model: nn.Module,\n    layers_to_remove: OrderedDict\n):\n    \"\"\"\n    Generic removal implementation\n    \"\"\"\n\n    for layer_name, layer_idx in layers_to_remove.items():\n        modules = layer_name.split(\".\")\n        mod = model\n        for m in modules[:-1]:\n            mod = getattr(mod, m)\n        \n        if layer_idx is None:\n            delattr(mod, modules[-1])\n        else:\n            delattr(mod, modules[-1])[layer_idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:56:17.163311Z","iopub.execute_input":"2025-03-15T11:56:17.163635Z","iopub.status.idle":"2025-03-15T11:56:17.168457Z","shell.execute_reply.started":"2025-03-15T11:56:17.163610Z","shell.execute_reply":"2025-03-15T11:56:17.167616Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def block_influence(\n    input_hidden_state: torch.Tensor,\n    output_hidden_state: torch.Tensor,\n    angular=False,\n):\n    \"\"\"\n    input_hidden_state: B, S, D\n    output_hidden_state: B, S, D\n    \"\"\"\n    _, _, d = input_hidden_state.shape\n    input_hidden_state = input_hidden_state.reshape(-1, d)\n    output_hidden_state = output_hidden_state.reshape(-1, d)\n\n    norm_input = input_hidden_state.norm(dim=-1, keepdim=True)\n    norm_output = output_hidden_state.norm(dim=-1, keepdim=True)\n\n    sim = (input_hidden_state @ output_hidden_state.T) / (norm_input * norm_output)\n    sim = sim.diagonal().nan_to_num(nan=0.5)\n\n    if angular:\n        return (torch.arccos(sim) / torch.pi)\n\n    return 1 - sim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:56:18.125501Z","iopub.execute_input":"2025-03-15T11:56:18.125812Z","iopub.status.idle":"2025-03-15T11:56:18.130773Z","shell.execute_reply.started":"2025-03-15T11:56:18.125787Z","shell.execute_reply":"2025-03-15T11:56:18.129891Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class ShortHFModel():\n\n    def __init__(self, model_name: str, layers_path: str, n_prune_layers: Optional[int] = None):\n        \"\"\"\n        HuggingFace Model Wrapper\n\n        Args:\n            model_name (str): HuggingFace model name\n            layers_path (str): String in dot notation demonstrating how to access layers of the model. Ex: \"model.layers\"\n            (Optional) n_prune_layers (int): Number of layers to prune. Defaults to None.\n        \"\"\"\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.tokenizer.pad_token = self.tokenizer.eos_token\n        self.model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n        # self.model.params = self.model.to_fp16(self.model.params)\n        self.model.to(\"cuda\")\n\n        modules = layers_path.split(\".\")\n        mod = self.model\n        for m in modules:\n            mod = getattr(mod, m)\n        self.layers = mod\n\n        self.n_prune_layers = n_prune_layers\n        self.importances = [0 for _ in self.layers]  # layer-wise importance scores\n\n    def remove_layers(\n        self,\n        layers_to_remove: Optional[List[int]] = [],\n        angular: Optional[bool] = False\n    ):\n        if angular:\n            assert self.importances, \"Need to compute importances with eval_importance()\"\n            assert self.n_prune_layers, \"Need number of layers to prune, set `n_prune_layers`\"\n            start_layer = np.argsort(np.array(self.importances[:-self.n_prune_layers+1]))[0]\n            layers_to_remove = list(range(start_layer, start_layer + self.n_prune_layers))\n        elif not layers_to_remove and self.n_prune_layers:\n            assert self.importances, \"Need to compute importances with eval_importance()\"\n            layers_to_remove = np.argsort(np.array(self.importances))[:self.n_prune_layers].tolist()\n\n        # remove layers in reverse to avoid indexing errors\n        for layer_idx in sorted(layers_to_remove, reverse=True):\n            try:\n                del self.layers[layer_idx]\n            except IndexError:\n                print(f\"layer {layer_idx} does not exist, function may have already been called\")\n                return []\n        \n        return layers_to_remove\n    \n    def compute_bi(self, hiddens: List[torch.Tensor], angular: bool):\n        n = 1\n        if angular:\n            assert self.n_prune_layers is not None, \"Set number of layers to prune to use angular importance\"\n            n = self.n_prune_layers\n\n        for i in range(len(hiddens) - n):\n            in_hidden = hiddens[i]\n            out_hidden = hiddens[i+n]\n            if angular:\n                # use only last token for angular distance as described in section 3.2\n                # https://arxiv.org/pdf/2403.17887.pdf\n                in_hidden = in_hidden[:,-1:]\n                out_hidden = out_hidden[:,-1:]\n            \n            self.importances[i] += block_influence(\n                in_hidden,\n                out_hidden,\n                angular=angular\n            ).sum().cpu().item()\n\n    @torch.inference_mode()\n    def eval_importance(\n        self,\n        prompts: List[str],\n        max_seq_len: int,\n        stride: int = 256,\n        max_gen_len: int = 0,\n        temperature: float = 0.6,\n        top_p: float = 0.9,\n        angular: Optional[bool] = False\n    ):\n        \"\"\"\n        Computes layer-wise importances over input texts.\n\n        NOTE: ShortGPT paper performs no generation during importance computation, which suggests a `max_gen_len`= 0.\n\n        Args:\n            prompts (List[str]): List of prompts.\n            max_seq_len (int): Maximum sequence length for model input, the sliding window size.\n            (Optional) stride (int): Number of tokens to skip/shift between each window inference.\n            (Optional) max_gen_len (int): Maximum length of the generated text sequence.\n            (Optional) temperature (float): Temperature value for controlling randomness in sampling. Defaults to 0.6.\n            (Optional) top_p (float): Top-p probability threshold for nucleus sampling. Defaults to 0.9.\n            (Optional) angular (bool): Whether to ues angular distance. Defaults to False.\n\n        Returns:\n            None\n        \"\"\"\n        prompt_tokens = self.tokenizer(\n            prompts,\n            padding=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        input_ids = prompt_tokens.input_ids\n        attn_mask = prompt_tokens.attention_mask\n\n        max_prompt_len = max(len(t) for t in input_ids)\n\n        # authors use a sliding window of size 1024 with a shift of 256\n        for start in range(0, max_prompt_len, stride):\n            seq_ids = (attn_mask.sum(dim=-1) > start).nonzero().squeeze()\n            seq_ids = seq_ids.unsqueeze(0) if seq_ids.dim() == 0 else seq_ids  # ensure 2d\n            inputs = input_ids[seq_ids, start:start+max_seq_len]\n            attn = attn_mask[seq_ids, start:start+max_seq_len]\n\n            if max_gen_len == 0:\n                outputs = self.model(\n                    input_ids=inputs.to(\"cuda\"),\n                    attention_mask=attn.to(\"cuda\"),\n                    output_hidden_states=True,\n                )\n            else:\n                outputs = self.model.generate(\n                    input_ids=inputs.to(\"cuda\"),\n                    attention_mask=attn.to(\"cuda\"),\n                    max_new_tokens=max_gen_len, \n                    do_sample=True,\n                    temperature=temperature,\n                    top_p=top_p,\n                    output_hidden_states=True,\n                    return_dict_in_generate=True,\n                )\n            \n            self.compute_bi(outputs.hidden_states, angular=angular)\n\n        return","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:56:20.249767Z","iopub.execute_input":"2025-03-15T11:56:20.250357Z","iopub.status.idle":"2025-03-15T11:56:20.275092Z","shell.execute_reply.started":"2025-03-15T11:56:20.250309Z","shell.execute_reply":"2025-03-15T11:56:20.274217Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data = load_dataset(\"pg19\",split=\"validation\",streaming=True).take(10) # loading the dataset.\ndataloader = DataLoader(\n    data,\n    batch_size=1,\n    #shuffle=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:56:23.778340Z","iopub.execute_input":"2025-03-15T11:56:23.778673Z","iopub.status.idle":"2025-03-15T11:56:29.863135Z","shell.execute_reply.started":"2025-03-15T11:56:23.778644Z","shell.execute_reply":"2025-03-15T11:56:29.862458Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59568b0183ed45ba8b34e6dfc3b420f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pg19.py:   0%|          | 0.00/6.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04721264c0784b24a8b5b476e4ea39d2"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for pg19 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/pg19.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"}],"execution_count":7},{"cell_type":"code","source":"MAX_SEQ_LEN = 1024\nshort_model = ShortHFModel(\n    model_name=\"meta-llama/Llama-3.2-3B\",\n    layers_path=\"model.layers\",\n    n_prune_layers=4,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:56:31.136553Z","iopub.execute_input":"2025-03-15T11:56:31.136866Z","iopub.status.idle":"2025-03-15T11:56:58.456145Z","shell.execute_reply.started":"2025-03-15T11:56:31.136842Z","shell.execute_reply":"2025-03-15T11:56:58.455209Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dfb6d5b68c842c1a5043a8c50754420"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06472333c4d948b095d0f836c622bb7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10eccbfd18de4212857aa5601936052c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b279db941e6f4242a4263e9bdef6fb5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf31eb6765f438e9b296727d1f1f6ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6f68a87b9243f38ee8c46442944b07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f427c9d465a41e0b33cacd37c732b14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cf2aa53cfec410793b21db4c4b63770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"290714809ced4c6dab324fbde3ea3ce6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57ae6cffeb4c4ef286a5308a9a188a35"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"short_model.model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:56:58.457132Z","iopub.execute_input":"2025-03-15T11:56:58.457389Z","iopub.status.idle":"2025-03-15T11:56:58.464033Z","shell.execute_reply.started":"2025-03-15T11:56:58.457368Z","shell.execute_reply":"2025-03-15T11:56:58.463255Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"short_model.model.config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:56:58.465452Z","iopub.execute_input":"2025-03-15T11:56:58.465676Z","iopub.status.idle":"2025-03-15T11:57:06.367816Z","shell.execute_reply.started":"2025-03-15T11:56:58.465656Z","shell.execute_reply":"2025-03-15T11:57:06.366667Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"LlamaConfig {\n  \"_attn_implementation_autoset\": true,\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.47.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# sample generation\ngen = short_model.model.generate(\n    short_model.tokenizer([\"Dhaka is the capital city of\"], return_tensors='pt').input_ids.to(\"cuda\"),\n    max_new_tokens=50\n)\nshort_model.tokenizer.batch_decode(gen, skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:57:06.369221Z","iopub.execute_input":"2025-03-15T11:57:06.369551Z","iopub.status.idle":"2025-03-15T11:57:09.155863Z","shell.execute_reply.started":"2025-03-15T11:57:06.369517Z","shell.execute_reply":"2025-03-15T11:57:09.155128Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['Dhaka is the capital city of Bangladesh. The city is situated on the banks of the Buriganga River, and the Padma River flows through the city. It is the largest city in Bangladesh and the most populous city in the country. Dhaka is also the cultural and economic']"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"for i, batch in enumerate(tqdm(dataloader)):\n    prompts = batch['text']\n\n    short_model.eval_importance(\n        prompts=prompts,\n        max_seq_len=MAX_SEQ_LEN,\n        stride=256,\n        max_gen_len=0\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T11:57:09.156659Z","iopub.execute_input":"2025-03-15T11:57:09.156889Z","iopub.status.idle":"2025-03-15T13:21:36.486947Z","shell.execute_reply.started":"2025-03-15T11:57:09.156870Z","shell.execute_reply":"2025-03-15T13:21:36.486071Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2104b4782a0649bbbf6ad47f2b5b75cc"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (429039 > 131072). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"short_model.importances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:21:36.487777Z","iopub.execute_input":"2025-03-15T13:21:36.488115Z","iopub.status.idle":"2025-03-15T13:21:36.493352Z","shell.execute_reply.started":"2025-03-15T13:21:36.488082Z","shell.execute_reply":"2025-03-15T13:21:36.492673Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[3099771.578125,\n 1329948.076171875,\n 1063329.34765625,\n 1067733.48046875,\n 1131896.111328125,\n 1093777.150390625,\n 1044766.2802734375,\n 1005813.33203125,\n 852906.37109375,\n 816430.4790039062,\n 798295.890625,\n 895215.63671875,\n 773229.3061523438,\n 831006.26171875,\n 796643.4296875,\n 654673.4311523438,\n 502772.23876953125,\n 425554.48291015625,\n 399103.13525390625,\n 414931.64697265625,\n 307589.484375,\n 274580.3447265625,\n 252607.755859375,\n 269757.646484375,\n 289469.71728515625,\n 342819.599609375,\n 448260.12158203125,\n 1546466.08984375]"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"param_size = 0\nfor param in short_model.model.parameters():\n    param_size += param.nelement() * param.element_size()\n\nbuffer_size = 0\nfor buffer in short_model.model.buffers():\n    buffer_size += buffer.nelement() * buffer.element_size()\n\n# Total size in bytes to GB\nsize_all_gb = (param_size + buffer_size) / 1024**3\nprint('Model size: {:.3f} GB'.format(size_all_gb))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:21:36.494145Z","iopub.execute_input":"2025-03-15T13:21:36.494456Z","iopub.status.idle":"2025-03-15T13:21:36.512252Z","shell.execute_reply.started":"2025-03-15T13:21:36.494426Z","shell.execute_reply":"2025-03-15T13:21:36.511477Z"}},"outputs":[{"name":"stdout","text":"Model size: 5.984 GB\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"short_model.remove_layers()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:21:36.514264Z","iopub.execute_input":"2025-03-15T13:21:36.514514Z","iopub.status.idle":"2025-03-15T13:21:36.528446Z","shell.execute_reply.started":"2025-03-15T13:21:36.514487Z","shell.execute_reply":"2025-03-15T13:21:36.527578Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[22, 23, 21, 24]"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"short_model.layers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:21:36.529692Z","iopub.execute_input":"2025-03-15T13:21:36.529979Z","iopub.status.idle":"2025-03-15T13:21:36.546087Z","shell.execute_reply.started":"2025-03-15T13:21:36.529949Z","shell.execute_reply":"2025-03-15T13:21:36.545485Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"ModuleList(\n  (0-23): 24 x LlamaDecoderLayer(\n    (self_attn): LlamaSdpaAttention(\n      (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n      (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n      (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n      (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n      (rotary_emb): LlamaRotaryEmbedding()\n    )\n    (mlp): LlamaMLP(\n      (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n      (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n      (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n      (act_fn): SiLU()\n    )\n    (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n    (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n  )\n)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"short_model.model.config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:21:36.546828Z","iopub.execute_input":"2025-03-15T13:21:36.547042Z","iopub.status.idle":"2025-03-15T13:21:36.562462Z","shell.execute_reply.started":"2025-03-15T13:21:36.547013Z","shell.execute_reply":"2025-03-15T13:21:36.561808Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"LlamaConfig {\n  \"_attn_implementation_autoset\": true,\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.47.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# reassign layer_idx to attentions for caching\nfor layer_idx, module in enumerate(short_model.layers):\n    module.self_attn.layer_idx = layer_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:21:36.563376Z","iopub.execute_input":"2025-03-15T13:21:36.563669Z","iopub.status.idle":"2025-03-15T13:21:36.576507Z","shell.execute_reply.started":"2025-03-15T13:21:36.563642Z","shell.execute_reply":"2025-03-15T13:21:36.575830Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"short_model.model.config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:21:36.577339Z","iopub.execute_input":"2025-03-15T13:21:36.577610Z","iopub.status.idle":"2025-03-15T13:21:36.592971Z","shell.execute_reply.started":"2025-03-15T13:21:36.577591Z","shell.execute_reply":"2025-03-15T13:21:36.592238Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"LlamaConfig {\n  \"_attn_implementation_autoset\": true,\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.47.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"gen = short_model.model.generate(\n    short_model.tokenizer([\"Dhaka is the capital city of\"], return_tensors='pt').input_ids.to(\"cuda\"),\n    max_new_tokens=50,\n    use_cache=True\n)\nshort_model.tokenizer.batch_decode(gen, skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:21:36.593663Z","iopub.execute_input":"2025-03-15T13:21:36.593847Z","iopub.status.idle":"2025-03-15T13:21:38.043070Z","shell.execute_reply.started":"2025-03-15T13:21:36.593831Z","shell.execute_reply":"2025-03-15T13:21:38.042375Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[\"Dhaka is the capital city of Bangladesh. It's a huge sprawling metropolis with millions of inhabitants. If you've ever visited the area you probably've noticed its beauty and wonderment. It's a perfect place for you to visit next time you visit.\\nIf you have never before\"]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"param_size = 0\nfor param in short_model.model.parameters():\n    param_size += param.nelement() * param.element_size()\n\nbuffer_size = 0\nfor buffer in short_model.model.buffers():\n    buffer_size += buffer.nelement() * buffer.element_size()\n\n# Total size in bytes to GB\nsize_all_gb = (param_size + buffer_size) / 1024**3\nprint('Model size: {:.3f} GB'.format(size_all_gb))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:34:31.277254Z","iopub.execute_input":"2025-03-15T13:34:31.277602Z","iopub.status.idle":"2025-03-15T13:34:31.284344Z","shell.execute_reply.started":"2025-03-15T13:34:31.277573Z","shell.execute_reply":"2025-03-15T13:34:31.283507Z"}},"outputs":[{"name":"stdout","text":"Model size: 5.234 GB\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"short_model.model.config.num_hidden_layers = len(short_model.layers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:43:44.218245Z","iopub.execute_input":"2025-03-15T13:43:44.218564Z","iopub.status.idle":"2025-03-15T13:43:44.222230Z","shell.execute_reply.started":"2025-03-15T13:43:44.218541Z","shell.execute_reply":"2025-03-15T13:43:44.221395Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"short_model.model.config\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:43:53.811645Z","iopub.execute_input":"2025-03-15T13:43:53.811944Z","iopub.status.idle":"2025-03-15T13:43:53.817781Z","shell.execute_reply.started":"2025-03-15T13:43:53.811920Z","shell.execute_reply":"2025-03-15T13:43:53.816949Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"LlamaConfig {\n  \"_attn_implementation_autoset\": true,\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.47.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"param_size = 0\nfor param in short_model.model.parameters():\n    param_size += param.nelement() * param.element_size()\n\nbuffer_size = 0\nfor buffer in short_model.model.buffers():\n    buffer_size += buffer.nelement() * buffer.element_size()\n\n# Total size in bytes to GB\nsize_all_gb = (param_size + buffer_size) / 1024**3\nprint('Model size: {:.3f} GB'.format(size_all_gb))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:44:13.597580Z","iopub.execute_input":"2025-03-15T13:44:13.597868Z","iopub.status.idle":"2025-03-15T13:44:13.604681Z","shell.execute_reply.started":"2025-03-15T13:44:13.597845Z","shell.execute_reply":"2025-03-15T13:44:13.603805Z"}},"outputs":[{"name":"stdout","text":"Model size: 5.234 GB\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import os\nnew_model_name = 'short-llama-3.2-3B-final'\noutput_dir = './'+new_model_name\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nshort_model.model.save_pretrained(output_dir)\nshort_model.tokenizer.save_pretrained(output_dir)\n#new_config.save_pretrained(output_dir)\nprint(f\"Pruned model saved to {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:46:40.328456Z","iopub.execute_input":"2025-03-15T13:46:40.328778Z","iopub.status.idle":"2025-03-15T13:46:56.177865Z","shell.execute_reply.started":"2025-03-15T13:46:40.328755Z","shell.execute_reply":"2025-03-15T13:46:56.176561Z"}},"outputs":[{"name":"stdout","text":"Pruned model saved to ./short-llama-3.2-3B-final\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Push the model to your Hugging Face repository\n\nshort_model.model.push_to_hub(new_model_name, private=False)\nshort_model.tokenizer.push_to_hub(new_model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:46:56.178768Z","iopub.execute_input":"2025-03-15T13:46:56.179064Z","iopub.status.idle":"2025-03-15T13:47:55.669023Z","shell.execute_reply.started":"2025-03-15T13:46:56.179040Z","shell.execute_reply":"2025-03-15T13:47:55.668119Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"581202a97f5a4d5197689a4f1b992757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/654M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e9ea55ad79345969a548ffda923e8ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"045965d6416c4cdca9c9ffe3d4bd3944"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5316466500c8483bb8cf3ff3f0a107a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"177414fe8c0f494bbca5de9ae057dee0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23c537a4eb104f39bbe7a7a8a4f24a40"}},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Shahrukh0/short-llama-3.2-3B-final/commit/fa4021cc848eb993d991a3b758c7cf24532cf4f4', commit_message='Upload tokenizer', commit_description='', oid='fa4021cc848eb993d991a3b758c7cf24532cf4f4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Shahrukh0/short-llama-3.2-3B-final', endpoint='https://huggingface.co', repo_type='model', repo_id='Shahrukh0/short-llama-3.2-3B-final'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"def evaluate_hf_model(model_name, tasks, num_fewshot=0):\n    \"\"\"\n    It calls the evaluator to evaluate a model available on Hugging Face.\n\n    Args:\n    - model_name: The model name in hugging Face.\n    - tasks: Tasks to evaluate.\n    - num_fewshot: Number of examples of few-shot learning\n\n    Returns:\n    - metrics.\n    \"\"\"\n    model_args = f\"pretrained={model_name},device=cuda\"\n    tasks = tasks\n\n    results = evaluator.simple_evaluate(\n      model=\"hf\",\n      model_args=model_args,\n      tasks=tasks,\n      num_fewshot=0,  # Number of few-shot smaples.\n      limit=None,  # Use all the samples in the Evaluate Dataset.\n      bootstrap_iters=10\n    )\n\n    metrics = results.get('results', {})\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:47:55.670829Z","iopub.execute_input":"2025-03-15T13:47:55.671066Z","iopub.status.idle":"2025-03-15T13:47:55.675287Z","shell.execute_reply.started":"2025-03-15T13:47:55.671048Z","shell.execute_reply":"2025-03-15T13:47:55.674288Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Select tasks to evaluate.\ntasks = ['lambada', 'boolq', 'arc_easy']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:47:55.676521Z","iopub.execute_input":"2025-03-15T13:47:55.676938Z","iopub.status.idle":"2025-03-15T13:47:55.697286Z","shell.execute_reply.started":"2025-03-15T13:47:55.676915Z","shell.execute_reply":"2025-03-15T13:47:55.696593Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"metrics_pruned = evaluate_hf_model(\"Shahrukh0/short-llama-3.2-3B-final\", tasks=tasks)\nmetrics_pruned","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T13:47:55.698105Z","iopub.execute_input":"2025-03-15T13:47:55.698421Z","iopub.status.idle":"2025-03-15T14:21:14.002329Z","shell.execute_reply.started":"2025-03-15T13:47:55.698391Z","shell.execute_reply":"2025-03-15T14:21:14.001227Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/884 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88037f82f2a4416ea6b2ecaff6886f03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b4f54ad1b2e4162b27eeef15a38eed9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3325a1ccf404e5ea52566175bdc97eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/335 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66cf9d4558b54f35b03fbae8bafe9354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/17.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe9e27b7cb74a54ad87f93c52180b1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72caea4cda6c4cb88e9b9c30c2543348"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6975e53abde34297af49119dcf9c00db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/654M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd57fc06497f49af865b4283241c22be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00e804b972544ee293dcee0c2429ca94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/180 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8de0804ccf3d4c5798d15334189b9c1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.99k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77dd5764f6e640119a82ceb415f415a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"lambada_openai.py:   0%|          | 0.00/4.82k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6d8d3a50c4340b1be7eb41305baef2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89634e353bb64ebe8f8e0202586d3ed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5153 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c75f3923d934d409a6b484e56f09258"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bbdddce52fb494cb7c1f82164d87ad3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00002.parquet:   0%|          | 0.00/269M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bf4582511204ceea06d49e431dde0c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00002.parquet:   0%|          | 0.00/281M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76b5c165ce24465c8dc3792b3bc635c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b77babdc7a849d686326b8d01b0df1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f73661b0ed9d4015a192eabf2641cedb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2662 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"830c3988f2984fe5a0627eff1d4646cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5153 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"603161a99c364808ad72f6ad50683105"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/4869 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01c5a1a3d40b4d8a9599a2e330197706"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/18.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c9c16d51ad14ff2941a121cebfae3cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"super_glue.py:   0%|          | 0.00/30.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61e4d044563b4b86a754d36cd35966fc"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e15c4e8b8304b29a000a498781272b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/9427 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e5886f6f4294991ad2a114854c23a85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3270 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd9edb8cd6214984b65a8441e7201d38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3245 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b033ec6e240049ad8c7f601ca37c6372"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d139ddd19ce84fbca044c39164d5d964"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/331k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cc4d7c223f04f6db783f7e13d37ef74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/346k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbff395ad3c64233b9cb43d6698f17f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/86.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50bf1998570e401a9ac60ee481426196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2251 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"855cacf1d5e64ac99dea94037e292df1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2376 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f651454b34d492999f41c5be7455008"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8bf786847be480ab25fe96076c7edc6"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 2376/2376 [00:02<00:00, 1036.33it/s]\n100%|██████████| 3270/3270 [00:01<00:00, 1877.11it/s]\n100%|██████████| 5153/5153 [00:09<00:00, 544.15it/s]\n100%|██████████| 5153/5153 [00:09<00:00, 548.73it/s]\nRunning loglikelihood requests: 100%|██████████| 26347/26347 [31:09<00:00, 14.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"bootstrapping for stddev: perplexity\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 81.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"bootstrapping for stddev: perplexity\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 94.80it/s]\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'arc_easy': {'alias': 'arc_easy',\n  'acc,none': 0.6254208754208754,\n  'acc_stderr,none': 0.00993175882041061,\n  'acc_norm,none': 0.6043771043771043,\n  'acc_norm_stderr,none': 0.01003374139343099},\n 'boolq': {'alias': 'boolq',\n  'acc,none': 0.6168195718654435,\n  'acc_stderr,none': 0.008503021391450788},\n 'lambada_openai': {'alias': 'lambada_openai',\n  'perplexity,none': 75.38296030401096,\n  'perplexity_stderr,none': 3.2598758114985995,\n  'acc,none': 0.30506501067339414,\n  'acc_stderr,none': 0.00641475925077358},\n 'lambada_standard': {'alias': 'lambada_standard',\n  'perplexity,none': 145.13123256545822,\n  'perplexity_stderr,none': 8.207591497933823,\n  'acc,none': 0.2549970890743256,\n  'acc_stderr,none': 0.0060723761944656935}}"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}